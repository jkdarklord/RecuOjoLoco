package test;

import org.apache.log4j.BasicConfigurator;
import javax.swing.JOptionPane;

import edu.uci.ics.crawler4j.crawler.CrawlConfig;
import edu.uci.ics.crawler4j.crawler.CrawlController;
import edu.uci.ics.crawler4j.fetcher.PageFetcher;
import edu.uci.ics.crawler4j.robotstxt.RobotstxtConfig;
import edu.uci.ics.crawler4j.robotstxt.RobotstxtServer;
import java.io.File;
import java.nio.file.Path;
import java.nio.file.Paths;

public class Controller {

    public void startCrawling(String seed, int crawlerCount, boolean limitCrawling, int documentMax, String directoryName) throws Exception {
            String crawlStorageFolder = "/data/";
            int numberOfCrawlers = crawlerCount;
            BasicConfigurator.configure();

            CrawlConfig config = new CrawlConfig();
            config.setCrawlStorageFolder(crawlStorageFolder);

            PageFetcher pageFetcher = new PageFetcher(config);
            RobotstxtConfig robotstxtConfig = new RobotstxtConfig();
            RobotstxtServer robotstxtServer = new RobotstxtServer(robotstxtConfig, pageFetcher);
            CrawlController controller = new CrawlController(config, pageFetcher, robotstxtServer);

            controller.addSeed(seed);
            
            setParameters(seed,crawlerCount,limitCrawling,documentMax,directoryName);
            
            controller.start(MyCrawler.class, numberOfCrawlers);
    }
    
    
    public void setParameters(String seed, int crawlerCount, boolean limitCrawling, int documentMax, String directoryName){
        MyCrawler.urlDomain = seed;
        MyCrawler.directory = new File(seed);
        MyCrawler.limit=limitCrawling;
        MyCrawler.maxCount=documentMax;
        Path currentRelativePath = Paths.get("");
        MyCrawler.directory = new File(currentRelativePath.toAbsolutePath().toString()+"\\"+directoryName);
        MyCrawler.directory.mkdirs();
    }
}